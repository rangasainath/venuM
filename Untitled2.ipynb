{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.applications.vgg19 import preprocess_input\n",
    "from keras import Sequential\n",
    "from keras.layers import Flatten, Dense\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "train_dir = '../input/face-mask-12k-images-dataset/Face Mask Dataset/Train'\n",
    "test_dir = '../input/face-mask-12k-images-dataset/Face Mask Dataset/Test'\n",
    "val_dir = '../input/face-mask-12k-images-dataset/Face Mask Dataset/Validation'\n",
    "train_datagen = ImageDataGenerator(rescale=1.0/255, horizontal_flip=True, zoom_range=0.2,shear_range=0.2)\n",
    "train_generator = train_datagen.flow_from_directory(directory=train_dir,target_size=(128,128),class_mode='categorical',batch_size=32)\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1.0/255)\n",
    "val_generator = train_datagen.flow_from_directory(directory=val_dir,target_size=(128,128),class_mode='categorical',batch_size=32)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1.0/255)\n",
    "test_generator = train_datagen.flow_from_directory(directory=val_dir,target_size=(128,128),class_mode='categorical',batch_size=32)\n",
    "vgg19 = VGG19(weights='imagenet',include_top=False,input_shape=(128,128,3))\n",
    "\n",
    "for layer in vgg19.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "model = Sequential()\n",
    "model.add(vgg19)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(2,activation='sigmoid'))\n",
    "model.summary()\n",
    "model.compile(optimizer=\"adam\",loss=\"categorical_crossentropy\",metrics =\"accuracy\")\n",
    "history = model.fit_generator(generator=train_generator,steps_per_epoch=len(train_generator)//32,epochs=20,validation_data=val_generator,validation_steps=len(val_generator)//32)\n",
    "model.evaluate_generator(test_generator)\n",
    "sample_mask_img = cv2.imread('../input/face-mask-12k-images-dataset/Face Mask Dataset/Test/WithMask/1565.png')\n",
    "sample_mask_img = cv2.resize(sample_mask_img,(128,128))\n",
    "plt.imshow(sample_mask_img)\n",
    "sample_mask_img = np.reshape(sample_mask_img,[1,128,128,3])\n",
    "sample_mask_img = sample_mask_img/255.0\n",
    "model.predict(sample_mask_img)\n",
    "model.save('masknet.h5')\n",
    "mask_label = {0:'MASK',1:'NO MASK'}\n",
    "dist_label = {0:(0,255,0),1:(255,0,0)}\n",
    "if len(faces)>=2:\n",
    "    label = [0 for i in range(len(faces))]\n",
    "    for i in range(len(faces)-1):\n",
    "        for j in range(i+1, len(faces)):\n",
    "            dist = distance.euclidean(faces[i][:2],faces[j][:2])\n",
    "            if dist<MIN_DISTANCE:\n",
    "                label[i] = 1\n",
    "                label[j] = 1\n",
    "    new_img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR) #colored output image\n",
    "    for i in range(len(faces)):\n",
    "        (x,y,w,h) = faces[i]\n",
    "        crop = new_img[y:y+h,x:x+w]\n",
    "        crop = cv2.resize(crop,(128,128))\n",
    "        crop = np.reshape(crop,[1,128,128,3])/255.0\n",
    "        mask_result = model.predict(crop)\n",
    "        cv2.putText(new_img,mask_label[mask_result.argmax()],(x, y-10),cv2.FONT_HERSHEY_SIMPLEX,0.5,dist_label[label[i]],2)\n",
    "        cv2.rectangle(new_img,(x,y),(x+w,y+h),dist_label[label[i]],1)\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.imshow(new_img)\n",
    "            \n",
    "else:\n",
    "    print(\"No. of faces detected is less than 2\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
